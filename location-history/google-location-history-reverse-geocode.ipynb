{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse-geocode Google location history\n",
    "\n",
    "See [this blog post](http://geoffboeing.com/2016/06/mapping-google-location-history-python/) for my full write-up of this project, or [this one](http://geoffboeing.com/2014/08/reverse-geocode-a-set-of-lat-long-coordinates-to-city-country/) for more about reverse-geocoding with Google.\n",
    "\n",
    "In the previous notebook, we clustered the location history data to reduce the size of the data set. This reduced set was saved as 'location-history-clustered.csv'. Now we'll reverse-geocode it from lat/long to neighborhood, city, state, country. First, this script copies that csv file and renames the copy 'google-history-to-geocode.csv'. It uses this file as our working file to do the reverse-geocoding and takes full advantage of local caching of results to prevent duplicate API calls during multiple runs. As Google limits your IP address to 2,500 requests per day, we might need to do the entire data set in multiple passes. Hence the working file.\n",
    "\n",
    "Sample API request: https://maps.googleapis.com/maps/api/geocode/json?latlng=39.9058153,-86.054788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, time, requests, json, os.path, logging as lg, datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause = 0.1 #google limits you to 10 requests per second\n",
    "use_second_geocoder = False #only set True on your last pass, if multiple\n",
    "max_google_requests = 2500 #how many requests to make of google\n",
    "google_requests_count = 0\n",
    "final_output_filename = 'data/google-location-history.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure local caching\n",
    "geocode_cache_filename = 'data/reverse_geocode_cache.js'\n",
    "cache_save_frequency = 100\n",
    "requests_count = 0\n",
    "geocode_cache = json.load(open(geocode_cache_filename)) if os.path.isfile(geocode_cache_filename) else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a logger to capture progress\n",
    "log = lg.getLogger('reverse_geocoder')\n",
    "if not getattr(log, 'handler_set', None):\n",
    "    todays_date = dt.datetime.today().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    log_filename = 'logs/reverse_geocoder_{}.log'.format(todays_date)\n",
    "    handler = lg.FileHandler(log_filename, encoding='utf-8')\n",
    "    formatter = lg.Formatter('%(asctime)s %(levelname)s %(name)s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    log.addHandler(handler)\n",
    "    log.setLevel(lg.INFO)\n",
    "    log.handler_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the working file (see note at top of notebook)\n",
    "working_filename = 'data/google-history-to-geocode.csv'\n",
    "if not os.path.isfile(working_filename):\n",
    "    df_temp = pd.read_csv('data/location-history-clustered.csv', encoding='utf-8')\n",
    "    df_temp.to_csv(working_filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saves the dict cache to disk as json\n",
    "def save_cache_to_disk(cache, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as cache_file:\n",
    "        cache_file.write(json.dumps(cache))\n",
    "    log.info('saved {:,} cached items to {}'.format(len(cache.keys()), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a http request\n",
    "def make_request(url):\n",
    "    log.info('requesting {}'.format(url))\n",
    "    return requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse neighborhood data from a google reverse-geocode result\n",
    "def get_neighborhood_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'neighborhood' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_1' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'sublocality_level_2' in component['types']:\n",
    "                    return component['long_name']                \n",
    "\n",
    "# parse city data from a google reverse-geocode result\n",
    "# to find city, return the finest-grain address component \n",
    "# google returns these components in order from finest to coarsest grained\n",
    "def get_city_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'locality' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'postal_town' in component['types']:\n",
    "                    return component['long_name']              \n",
    "                elif 'administrative_area_level_5' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_4' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    return component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    return component['long_name']\n",
    "\n",
    "# parse state data from a google reverse-geocode result                \n",
    "# to find state, you want the lowest-level admin area available\n",
    "# but, google returns admin areas listed from highest-level to lowest\n",
    "# so you can't just return as soon as you find the first match\n",
    "# this is is opposite of the previous, because this time we want the coarsest-grain match\n",
    "# otherwise we end up with counties and so forth instead of states\n",
    "def get_state_google(result):\n",
    "    if pd.notnull(result):\n",
    "        state = None\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'administrative_area_level_1' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_2' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'administrative_area_level_3' in component['types']:\n",
    "                    state = component['long_name']\n",
    "                elif 'locality' in component['types']:\n",
    "                    state = component['long_name']\n",
    "        return state\n",
    "\n",
    "# parse country data from a google reverse-geocode result\n",
    "def get_country_google(result):\n",
    "    if pd.notnull(result):\n",
    "        if 'address_components' in result:\n",
    "            for component in result['address_components']:\n",
    "                if 'country' in component['types']:\n",
    "                    return component['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse city, state, country data from a nominatim reverse-geocode result\n",
    "def parse_nominatim_data(data):\n",
    "    country = None\n",
    "    state = None\n",
    "    city = None\n",
    "    if isinstance(data, dict):\n",
    "        if 'address' in data:\n",
    "            if 'country' in data['address']:\n",
    "                country = data['address']['country']\n",
    "\n",
    "            #state\n",
    "            if 'region' in data['address']:\n",
    "                state = data['address']['region']\n",
    "            if 'state' in data['address']:\n",
    "                state = data['address']['state']\n",
    "\n",
    "            #city\n",
    "            if 'county' in data['address']:\n",
    "                county = data['address']['county']\n",
    "            if 'village' in data['address']:\n",
    "                city = data['address']['village']\n",
    "            if 'city' in data['address']:\n",
    "                city = data['address']['city']\n",
    "    return city, state, country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass latlng data to osm nominatim to reverse geocode it\n",
    "def reverse_geocode_nominatim(latlng):\n",
    "\n",
    "    time.sleep(pause)\n",
    "    url = 'https://nominatim.openstreetmap.org/reverse?format=json&lat={}&lon={}&zoom=18&addressdetails=1'\n",
    "    data = make_request(url.format(latlng.split(',')[0], latlng.split(',')[1]))\n",
    "\n",
    "    place = {}\n",
    "    place['neighborhood'] = None\n",
    "    place['city'], place['state'], place['country'] = parse_nominatim_data(data)\n",
    "    return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass the Google API latlng data to reverse geocode it\n",
    "def reverse_geocode_google(latlng):\n",
    "    \n",
    "    global google_requests_count\n",
    "    \n",
    "    if google_requests_count < max_google_requests:\n",
    "        # we have not yet made the max # of requests\n",
    "        time.sleep(pause)\n",
    "        google_requests_count += 1\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}'\n",
    "        data = make_request(url.format(latlng))\n",
    "        if len(data['results']) > 0:\n",
    "            result = data['results'][0]\n",
    "            \n",
    "            place = {}\n",
    "            place['neighborhood'] = get_neighborhood_google(result)\n",
    "            place['city'] = get_city_google(result)\n",
    "            place['state'] = get_state_google(result)\n",
    "            place['country'] = get_country_google(result)\n",
    "            return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reverse_geocode(latlng, reverse_geocode_function=reverse_geocode_google, use_cache=True):\n",
    "    \n",
    "    global geocode_cache, requests_count\n",
    "    \n",
    "    if use_cache and latlng in geocode_cache and pd.notnull(geocode_cache[latlng]):\n",
    "        log.info('retrieving results from cache for lat-long \"{}\"'.format(latlng))\n",
    "        return geocode_cache[latlng]\n",
    "    else:\n",
    "        place = reverse_geocode_function(latlng)\n",
    "        geocode_cache[latlng] = place\n",
    "        log.info('stored place details in cache for lat-long \"{}\"'.format(latlng))\n",
    "        \n",
    "        requests_count += 1\n",
    "        if requests_count % cache_save_frequency == 0: \n",
    "            save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "            \n",
    "        return place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_place_by_latlng(latlng, component):\n",
    "    try:\n",
    "        return place_dict[latlng][component]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data for geocoding\n",
    "\n",
    "If there are more than 2,500 rows in the dataset, you need to run this notebook multiple times because Google limits you to 2,500 requests per day. Or fall back on the nominatim API, with `use_second_geocoder=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,714 rows in dataset\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(working_filename, encoding='utf-8')\n",
    "print('{:,} rows in dataset'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp_s</th>\n",
       "      <th>datetime</th>\n",
       "      <th>altitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latlng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.863050</td>\n",
       "      <td>-122.274165</td>\n",
       "      <td>1384967149</td>\n",
       "      <td>2013-11-20 17:05:49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>South Berkeley</td>\n",
       "      <td>37.8630503,-122.2741654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.661579</td>\n",
       "      <td>96.927100</td>\n",
       "      <td>1432172179</td>\n",
       "      <td>2015-05-21 01:36:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nyaungshwe</td>\n",
       "      <td>Shan</td>\n",
       "      <td>Myanmar (Burma)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6615786,96.9271002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.702719</td>\n",
       "      <td>-73.993195</td>\n",
       "      <td>1481762812</td>\n",
       "      <td>2016-12-15 00:46:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.7027194,-73.9931954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.806071</td>\n",
       "      <td>-122.275315</td>\n",
       "      <td>1376865520</td>\n",
       "      <td>2013-08-18 22:38:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>Downtown Oakland</td>\n",
       "      <td>37.8060707,-122.2753146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.783432</td>\n",
       "      <td>-73.979008</td>\n",
       "      <td>1414960327</td>\n",
       "      <td>2014-11-02 20:32:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.7834318,-73.9790079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat         lon  timestamp_s             datetime  altitude  \\\n",
       "0  37.863050 -122.274165   1384967149  2013-11-20 17:05:49       NaN   \n",
       "1  20.661579   96.927100   1432172179  2015-05-21 01:36:19       NaN   \n",
       "2  40.702719  -73.993195   1481762812  2016-12-15 00:46:52       NaN   \n",
       "3  37.806071 -122.275315   1376865520  2013-08-18 22:38:40       NaN   \n",
       "4  40.783432  -73.979008   1414960327  2014-11-02 20:32:07       NaN   \n",
       "\n",
       "         city       state          country      neighborhood  \\\n",
       "0    Berkeley  California    United States    South Berkeley   \n",
       "1  Nyaungshwe        Shan  Myanmar (Burma)               NaN   \n",
       "2         NaN         NaN              NaN               NaN   \n",
       "3     Oakland  California    United States  Downtown Oakland   \n",
       "4         NaN         NaN              NaN               NaN   \n",
       "\n",
       "                    latlng  \n",
       "0  37.8630503,-122.2741654  \n",
       "1    20.6615786,96.9271002  \n",
       "2   40.7027194,-73.9931954  \n",
       "3  37.8060707,-122.2753146  \n",
       "4   40.7834318,-73.9790079  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create city, state, country columns only if they don't already exist\n",
    "new_cols = ['city', 'state', 'country', 'neighborhood']\n",
    "for col in new_cols:\n",
    "    if not col in df.columns:\n",
    "        df[col] = None\n",
    "        \n",
    "# drop the locations and timestamp_ms columns if they are still here\n",
    "cols_to_remove = ['locations', 'timestamp_ms']\n",
    "for col in cols_to_remove:\n",
    "    if col in df.columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put latlng in the format google likes so it's easy to call their api\n",
    "# and round to 7 decimal places so our cache's keys are consistent\n",
    "# (so you don't get weird float precision artifacts like 114.1702368000000001)\n",
    "df['latlng'] = df.apply(lambda row: '{:.7f},{:.7f}'.format(row['lat'], row['lon']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,251 out of 4,714 rows lack reverse-geocode results\n",
      "We will attempt to reverse-geocode up to 2,500 rows with Google\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))\n",
    "print('We will attempt to reverse-geocode up to {:,} rows with Google'.format(max_google_requests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now reverse-geocode the location history with the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_latlngs = df['latlng'].dropna().sort_values().unique()\n",
    "place_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for latlng in unique_latlngs:\n",
    "    place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "    df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of 4,714 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next reverse-geocode missing rows with the Nominatim API\n",
    "\n",
    "If use_second_geocoder is True, use OSM Nominatum API to reverse-geocode any remaining missing rows. Only do this on the final pass. This is useful for places like Kosovo that Google does not return results for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_second_geocoder:\n",
    "    unique_latlngs = ungeocoded_rows['latlng'].dropna().sort_values().unique()\n",
    "    for latlng in unique_latlngs:\n",
    "        place_dict[latlng] = reverse_geocode(latlng, reverse_geocode_nominatim)\n",
    "    for component in ['country', 'state', 'city', 'neighborhood']:\n",
    "        df[component] = df['latlng'].apply(get_place_by_latlng, args=(component,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 4,714 rows still lack reverse-geocode results\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isnull(df['country']) & pd.isnull(df['state']) & pd.isnull(df['city']) & pd.isnull(df['neighborhood'])\n",
    "ungeocoded_rows = df[mask]\n",
    "print('{:,} out of {:,} rows still lack reverse-geocode results'.format(len(ungeocoded_rows), len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done: Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timestamp_s</th>\n",
       "      <th>datetime</th>\n",
       "      <th>altitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>latlng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>-25.580172</td>\n",
       "      <td>-54.553888</td>\n",
       "      <td>1389454801</td>\n",
       "      <td>2014-01-11 15:40:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foz do Iguaçu</td>\n",
       "      <td>Paraná</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Jardim Residencial Cataratas</td>\n",
       "      <td>-25.5801722,-54.5538881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>34.257032</td>\n",
       "      <td>-119.219203</td>\n",
       "      <td>1451759768</td>\n",
       "      <td>2016-01-02 18:36:08</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>34.2570319,-119.2192028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>32.970251</td>\n",
       "      <td>-112.673138</td>\n",
       "      <td>1451438002</td>\n",
       "      <td>2015-12-30 01:13:22</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Gila Bend</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>32.9702512,-112.6731377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>33.393090</td>\n",
       "      <td>-111.863682</td>\n",
       "      <td>1450828602</td>\n",
       "      <td>2015-12-22 23:56:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mesa</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>33.3930905,-111.8636819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4713</th>\n",
       "      <td>-25.550379</td>\n",
       "      <td>-54.559682</td>\n",
       "      <td>1389452988</td>\n",
       "      <td>2014-01-11 15:09:48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Foz do Iguaçu</td>\n",
       "      <td>Paraná</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>None</td>\n",
       "      <td>-25.5503785,-54.5596820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lat         lon  timestamp_s             datetime  altitude  \\\n",
       "4709 -25.580172  -54.553888   1389454801  2014-01-11 15:40:01       NaN   \n",
       "4710  34.257032 -119.219203   1451759768  2016-01-02 18:36:08      12.0   \n",
       "4711  32.970251 -112.673138   1451438002  2015-12-30 01:13:22     202.0   \n",
       "4712  33.393090 -111.863682   1450828602  2015-12-22 23:56:42       NaN   \n",
       "4713 -25.550379  -54.559682   1389452988  2014-01-11 15:09:48       NaN   \n",
       "\n",
       "               city       state        country                  neighborhood  \\\n",
       "4709  Foz do Iguaçu      Paraná         Brazil  Jardim Residencial Cataratas   \n",
       "4710        Ventura  California  United States                          None   \n",
       "4711      Gila Bend     Arizona  United States                          None   \n",
       "4712           Mesa     Arizona  United States                          None   \n",
       "4713  Foz do Iguaçu      Paraná         Brazil                          None   \n",
       "\n",
       "                       latlng  \n",
       "4709  -25.5801722,-54.5538881  \n",
       "4710  34.2570319,-119.2192028  \n",
       "4711  32.9702512,-112.6731377  \n",
       "4712  33.3930905,-111.8636819  \n",
       "4713  -25.5503785,-54.5596820  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save cache to disk\n",
    "save_cache_to_disk(geocode_cache, geocode_cache_filename)\n",
    "\n",
    "# save the entire data set to the working file\n",
    "df.to_csv(working_filename, encoding='utf-8', index=False)\n",
    "\n",
    "# save the useful columns to a final output file\n",
    "cols_to_retain = ['datetime', 'neighborhood', 'city', 'state', 'country', 'lat', 'lon']\n",
    "df[cols_to_retain].to_csv(final_output_filename, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
